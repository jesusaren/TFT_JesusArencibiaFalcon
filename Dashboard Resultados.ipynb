{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Resultados TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x225e24b7b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bb2df4f3ed4a74a5732aeb88d3ec25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a78671d8a11457cb4c3aeb2777a2ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, dash_table\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "from prophet import Prophet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from dash import no_update\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import shap\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('df_final_prueba.csv')\n",
    "#df = df[df[\"tmed\"] != 0]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Identificar columnas de productos y características\n",
    "producto_cols = df.columns[37:]\n",
    "feature_cols = df.columns.difference(producto_cols.union(['date']))\n",
    "\n",
    "# Variables climatológicas\n",
    "clima_cols = ['tmed', 'tmin', 'tmax', 'prec', 'dir', 'velmedia', 'racha', 'presMax', 'presMin', 'hrMedia', 'sol']\n",
    "\n",
    "# Perfil de clientes para clustering\n",
    "perfil_cols = ['adults', 'children', 'babies'] + [col for col in df.columns if col.startswith('people_')]\n",
    "X_perfil = df[perfil_cols]\n",
    "\n",
    "# Escalado y PCA\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_perfil)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "df['cluster'] = clusters\n",
    "df['PCA1'] = X_pca[:, 0]\n",
    "df['PCA2'] = X_pca[:, 1]\n",
    "\n",
    "# Inicializar la app Dash\n",
    "app = dash.Dash(__name__, suppress_callback_exceptions=True)\n",
    "\n",
    "app.layout = html.Div(style={'fontFamily': 'Arial, sans-serif', 'backgroundColor': '#f7f7f7', 'padding': '20px'}, children=[\n",
    "    html.Div([\n",
    "        html.Img(src='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRFZy_SrbT2vGKakrE7lUj70sqTyn5QR4xBbQ&s', style={'height': '60px', 'marginRight': '20px'}),\n",
    "        html.H1(\"Dashboard de Análisis de Sensibilidad por Producto\", style={'display': 'inline-block', 'verticalAlign': 'middle'})\n",
    "    ], style={'display': 'flex', 'alignItems': 'center', 'marginBottom': '30px'}),\n",
    "\n",
    "    dcc.Tabs(id='tabs', value='main', children=[\n",
    "        dcc.Tab(label='Análisis de Sensibilidad', value='main'),\n",
    "        dcc.Tab(label='Análisis SHAP values', value='shap'),\n",
    "        dcc.Tab(label='Análisis de Productos', value='productos'),\n",
    "        dcc.Tab(label='Predicción de Ventas', value='prediccion')\n",
    "    ]),\n",
    "\n",
    "    html.Div(id='tab-content')\n",
    "])\n",
    "\n",
    "@app.callback(Output('tab-content', 'children'), Input('tabs', 'value'))\n",
    "def render_tab(tab):\n",
    "    if tab == 'main':\n",
    "        return html.Div([\n",
    "            html.H3(\"Análisis de variables más relevantes\"),\n",
    "            html.Div([\n",
    "                html.Div([\n",
    "                    html.Label(\"Selecciona un producto:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='producto-dropdown',\n",
    "                        options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                        value=producto_cols[0]\n",
    "                    ),\n",
    "                ], style={'width': '48%', 'display': 'inline-block', 'paddingRight': '2%'}),\n",
    "\n",
    "                html.Div([\n",
    "                    html.Label(\"Selecciona un cluster de clientes:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='cluster-dropdown',\n",
    "                        options=[{'label': f'Cluster {i}', 'value': i} for i in sorted(df['cluster'].unique())],\n",
    "                        value=None, placeholder=\"Todos los clusters\"\n",
    "                    ),\n",
    "                ], style={'width': '48%', 'display': 'inline-block'})\n",
    "            ], style={'marginBottom': '30px'}),\n",
    "\n",
    "            dcc.Graph(id='importancia-lineal', style={'marginBottom': '30px'}),\n",
    "            dcc.Graph(id='importancia-lineal-inversa', style={'marginBottom': '30px'}),\n",
    "            dcc.Graph(id='importancia-nolineal', style={'marginBottom': '30px'}),\n",
    "            dcc.Graph(id='importancia-xgboosts', style={'marginBottom': '30px'}),\n",
    "            dcc.Graph(id='importancia-lightGMb', style={'marginBottom': '30px'}),\n",
    "\n",
    "            dcc.Graph(id='grafico-mlp', style={'marginBottom': '30px'}),\n",
    "            dcc.Graph(id='cluster-pca'),\n",
    "            html.Div(id='score-modelos', style={'marginTop': '20px', 'fontSize': '18px', 'color': '#333'})\n",
    "        ])\n",
    "\n",
    "    elif tab == 'shap':\n",
    "        return html.Div([\n",
    "            html.H3(\"Análisis por modelo de SHAP Values\"),\n",
    "            html.Label(\"Selecciona un producto para ver SHAP values:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='producto-shap-dropdown',\n",
    "                options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                value=producto_cols[0],\n",
    "                style={'width': '60%', 'marginBottom': '30px'}\n",
    "            ),\n",
    "            html.Div([\n",
    "                html.H4(\"SHAP Summary Plot - Random Forest\"),\n",
    "                html.Img(id='shap-img-rf', style={\n",
    "                    'width': '60%', 'margin': 'auto', 'display': 'block', 'marginBottom': '30px'\n",
    "                }),\n",
    "                html.H4(\"SHAP Summary Plot - XGBoost\"),\n",
    "                html.Img(id='shap-img-xgb', style={\n",
    "                    'width': '60%', 'margin': 'auto', 'display': 'block', 'marginBottom': '30px'\n",
    "                }),\n",
    "                html.H4(\"SHAP Summary Plot - LightGBM\"),\n",
    "                html.Img(id='shap-img-lgbm', style={\n",
    "                    'width': '60%', 'margin': 'auto', 'display': 'block', 'marginBottom': '30px'\n",
    "                })\n",
    "            ])\n",
    "    ])\n",
    "\n",
    "\n",
    "    elif tab == 'productos':\n",
    "        return html.Div([\n",
    "            html.H3(\"Análisis de Ventas por Producto\"),\n",
    "            html.Div([\n",
    "                html.Label(\"Selecciona un producto:\"),\n",
    "                dcc.Dropdown(\n",
    "                id='producto-evolucion-dropdown',\n",
    "                options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                value=producto_cols[0],\n",
    "                style={'width': '60%', 'marginBottom': '20px'}\n",
    "                )\n",
    "            ]),\n",
    "            dcc.Graph(id='evolucion-ventas-producto'),\n",
    "            \n",
    "            html.H3(\"Segmentación de Productos por Comportamiento\"),\n",
    "            dcc.Graph(id='cluster-productos', figure=segmentacion_productos()),\n",
    "\n",
    "            html.H3(\"Top Productos por Ventas Totales\"),\n",
    "            dcc.Graph(figure=top_productos()),\n",
    "\n",
    "            html.H3(\"Comparativa entre Productos\"),\n",
    "            html.Div([\n",
    "                html.Label(\"Producto 1:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='producto1',\n",
    "                    options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                    value=producto_cols[0],\n",
    "                    style={'width': '45%', 'display': 'inline-block', 'marginRight': '5%'}\n",
    "                ),\n",
    "                html.Label(\"Producto 2:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='producto2',\n",
    "                    options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                    value=producto_cols[1],\n",
    "                    style={'width': '45%', 'display': 'inline-block'}\n",
    "                ),\n",
    "            ], style={'marginBottom': '20px'}),\n",
    "            dcc.Graph(id='comparativa-productos'),\n",
    "\n",
    "            html.Div([\n",
    "                html.Label(\"Selecciona un producto para análisis estacional y climático:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='producto-clima-dropdown',\n",
    "                    options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                    value=producto_cols[0]\n",
    "                )\n",
    "            ], style={'width': '60%', 'marginBottom': '30px'}),\n",
    "\n",
    "            dcc.Graph(id='grafico-estacionalidad'),\n",
    "\n",
    "            html.Div([\n",
    "                html.Label(\"Selecciona una variable climatológica para analizar su impacto en las ventas:\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='clima-variable-dropdown',\n",
    "                    options=[{'label': var, 'value': var} for var in clima_cols],\n",
    "                    value='sol'\n",
    "                )\n",
    "            ], style={'width': '60%', 'marginTop': '30px'}),\n",
    "\n",
    "            dcc.Graph(id='grafico-impacto-clima')\n",
    "\n",
    "        ])\n",
    "\n",
    "    elif tab == 'prediccion':\n",
    "        return html.Div([\n",
    "            html.H3(\"Análisis predictivo de ventas futuras\"),\n",
    "\n",
    "            html.Label(\"Selecciona un producto:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='producto-prediccion-dropdown',\n",
    "                options=[{'label': p, 'value': p} for p in producto_cols],\n",
    "                value=producto_cols[0],\n",
    "                style={'width': '60%', 'marginBottom': '20px'}\n",
    "            ),\n",
    "\n",
    "            html.Label(\"Selecciona el modelo de predicción:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='modelo-prediccion-dropdown',\n",
    "                options=[\n",
    "                    {'label': 'Prophet', 'value': 'prophet'},\n",
    "                    {'label': 'Ridge', 'value': 'ridge'},\n",
    "                    {'label': 'Random Forest', 'value': 'rf'},\n",
    "                    {'label': 'XGBoost', 'value': 'xgb'},\n",
    "                    {'label': 'LightGBM', 'value': 'lgbm'},\n",
    "                    {'label': 'MLP', 'value': 'mlp'}\n",
    "                ],\n",
    "                value='prophet',\n",
    "                style={'width': '60%', 'marginBottom': '30px'}\n",
    "            ),\n",
    "\n",
    "            dcc.Graph(id='prediccion-ventas'),\n",
    "\n",
    "            html.Div(id='tabla-predicciones-container')\n",
    "        ])\n",
    "\n",
    "\n",
    "def segmentacion_productos():\n",
    "    ventas = df[producto_cols]\n",
    "    ventas_scaled = StandardScaler().fit_transform(ventas.T)\n",
    "    pca = PCA(n_components=2)\n",
    "    ventas_pca = pca.fit_transform(ventas_scaled)\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(ventas_pca)\n",
    "    df_cluster = pd.DataFrame(ventas_pca, columns=['PCA1', 'PCA2'])\n",
    "    df_cluster['cluster'] = kmeans.labels_\n",
    "    df_cluster['producto'] = producto_cols\n",
    "    fig = px.scatter(df_cluster, x='PCA1', y='PCA2', color='cluster', hover_name='producto', title=\"Cluster de productos por comportamiento de ventas\")\n",
    "    return fig\n",
    "\n",
    "def top_productos():\n",
    "    total_ventas = df[producto_cols].sum().sort_values(ascending=True)\n",
    "    fig = px.bar(total_ventas, orientation='h', title=\"Top productos por ventas totales\",\n",
    "                 labels={'value': 'Ventas Totales', 'index': 'Producto'})\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('comparativa-productos', 'figure'),\n",
    "    [Input('producto1', 'value'), Input('producto2', 'value')]\n",
    ")\n",
    "def comparar(producto1, producto2):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df[producto1], mode='lines', name=producto1))\n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df[producto2], mode='lines', name=producto2))\n",
    "    fig.update_layout(title=f\"Comparativa entre {producto1} y {producto2}\", xaxis_title=\"Fecha\", yaxis_title=\"Ventas\")\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    [Output('importancia-lineal', 'figure'),\n",
    "     Output('importancia-lineal-inversa', 'figure'),\n",
    "     Output('importancia-nolineal', 'figure'),\n",
    "     Output('importancia-xgboosts', 'figure'), \n",
    "     Output('importancia-lightGMb', 'figure'),\n",
    "     Output('grafico-mlp', 'figure'),\n",
    "     Output('cluster-pca', 'figure')],\n",
    "     Output('score-modelos', 'children'),\n",
    "    [Input('producto-dropdown', 'value'),\n",
    "     Input('cluster-dropdown', 'value')]\n",
    ")\n",
    "def update_main_tab(producto, cluster):\n",
    "    df_filtered = df.copy()\n",
    "    if cluster is not None:\n",
    "        df_filtered = df_filtered[df_filtered['cluster'] == cluster]\n",
    "\n",
    "    q1, q3 = df_filtered[producto].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    df_filtered = df_filtered[(df_filtered[producto] >= q1 - 1.5 * iqr) & (df_filtered[producto] <= q3 + 1.5 * iqr)]\n",
    "\n",
    "    X = df_filtered[feature_cols]\n",
    "    y = df_filtered[producto]\n",
    "\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        mask = y_true != 0\n",
    "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "    # Modelo LinearRegression\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_lr = linreg.predict(X_test)\n",
    "    r2_lr = r2_score(y_test, y_pred_lr)\n",
    "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "    rmse_lr = root_mean_squared_error(y_test, y_pred_lr)\n",
    "    mape_lr = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "\n",
    "\n",
    "    coef_importancias = pd.Series(linreg.coef_, index=X.columns)\n",
    "\n",
    "    top_positivos = coef_importancias.sort_values(ascending=False).head(10)\n",
    "    fig_lineal = px.bar(top_positivos, title=f\"Importancia Lineal (Positivos) para: {producto}\",\n",
    "                        labels={'value': 'Coeficiente', 'index': 'Variable'})\n",
    "\n",
    "    top_negativos = coef_importancias.sort_values().head(10)\n",
    "    fig_lineal_inversa = px.bar(-top_negativos, title=f\"Importancia Lineal Inversa (Negativos) para: {producto}\",\n",
    "                                 labels={'value': 'Coeficiente invertido', 'index': 'Variable'}, color_discrete_sequence=['red'])\n",
    "\n",
    "    # Modelo Random Forest\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rf = model.predict(X_test)\n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    rmse_rf = root_mean_squared_error(y_test, y_pred_rf)\n",
    "    mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf)\n",
    "\n",
    "    rf_importancias = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\n",
    "    fig_nolineal = px.bar(rf_importancias.sort_values(ascending=False).head(10),\n",
    "                          title=f\"Importancia No Lineal (Random Forest) para: {producto}\",\n",
    "                          labels={'value': 'Importancia', 'index': 'Variable'})\n",
    "\n",
    "    fig_evolucion = px.line(df_filtered, x='date', y=producto, title=f\"Evolución de Ventas - {producto}\")\n",
    "\n",
    "    fig_cluster = px.scatter(df, x='PCA1', y='PCA2', color='cluster',\n",
    "                             title=\"Clusters de Perfiles de Clientes (PCA)\",\n",
    "                             labels={'PCA1': 'Componente Principal 1', 'PCA2': 'Componente Principal 2'})\n",
    "\n",
    "\n",
    "    # Modelo XGBoost\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    model_xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = model_xgb.predict(X_test)\n",
    "    \n",
    "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "    rmse_xgb = root_mean_squared_error(y_test, y_pred_xgb)\n",
    "    mape_xgb = mean_absolute_percentage_error(y_test, y_pred_xgb)\n",
    "\n",
    "    explainer_xgb = shap.Explainer(model_xgb)\n",
    "    shap_values_xgb = explainer_xgb(X_test)\n",
    "    shap_mean_importance = np.abs(shap_values_xgb.values).mean(axis=0)\n",
    "    xgb_importancias = pd.Series(shap_mean_importance, index=X.columns)\n",
    "    fig_xgBoost = px.bar(xgb_importancias.sort_values(ascending=False).head(10),\n",
    "                      title=f\"Importancia No Lineal (XGBoost - SHAP) para: {producto}\",\n",
    "                      labels={'value': 'Importancia Media Absoluta', 'index': 'Variable'})\n",
    "    \n",
    "    # Modelo LightGBM\n",
    "    model_lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "    model_lgbm.fit(X_train, y_train)\n",
    "    y_pred_lgbm = model_lgbm.predict(X_test)\n",
    "    \n",
    "    r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "    mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "    rmse_lgbm = root_mean_squared_error(y_test, y_pred_lgbm)\n",
    "    mape_lgbm = mean_absolute_percentage_error(y_test, y_pred_lgbm)\n",
    "\n",
    "    explainer_lgbm = shap.Explainer(model_lgbm)\n",
    "    shap_values_lgbm = explainer_lgbm(X_test)\n",
    "    shap_mean_importance_lgbm = np.abs(shap_values_lgbm.values).mean(axis=0)\n",
    "    lgbm_importancias = pd.Series(shap_mean_importance_lgbm, index=X.columns)\n",
    "\n",
    "    fig_lightGBM = px.bar(lgbm_importancias.sort_values(ascending=False).head(10),\n",
    "                          title=f\"Importancia No Lineal (LightGBM - SHAP) para: {producto}\",\n",
    "                          labels={'value': 'Importancia Media Absoluta', 'index': 'Variable'})\n",
    "\n",
    "    # Red Neuronal MLP\n",
    "    selector = SelectKBest(score_func=f_regression, k=20)\n",
    "    X_selected = selector.fit_transform(X, y.values.ravel())\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "    selected_features = X.columns.tolist()\n",
    "\n",
    "    scaler_X = RobustScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X[selected_features])\n",
    "    scaler_y = RobustScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "    X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(\n",
    "        X_tensor, y_tensor, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super().__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_dim, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 1)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "    model = MLP(X_train_tensor.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_r2 = -np.inf\n",
    "    patience = 20\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(300):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = model(X_test_tensor).numpy()\n",
    "            y_pred_inv = scaler_y.inverse_transform(y_pred_val)\n",
    "            y_true_inv = scaler_y.inverse_transform(y_test_tensor.numpy())\n",
    "            current_r2 = r2_score(y_true_inv, y_pred_inv)\n",
    "\n",
    "            if current_r2 > best_r2:\n",
    "                best_r2 = current_r2\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                trigger_times = 0\n",
    "            else:\n",
    "                trigger_times += 1\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor).numpy()\n",
    "        y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "        y_true_inv = scaler_y.inverse_transform(y_test_tensor.numpy())\n",
    "        r2_mlp = r2_score(y_true_inv, y_pred_inv)\n",
    "        \n",
    "    mae_mlp = mean_absolute_error(y_true_inv, y_pred_inv)\n",
    "    rmse_mlp = root_mean_squared_error(y_true_inv, y_pred_inv)\n",
    "    mape_mlp = mean_absolute_percentage_error(y_true_inv, y_pred_inv)\n",
    "\n",
    "    def predict_wrapper(X_numpy):\n",
    "        X_tensor = torch.tensor(X_numpy, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_tensor).detach().numpy()\n",
    "        return preds.flatten()\n",
    "\n",
    "    np.random.seed(42)\n",
    "    X_background = X_scaled[np.random.choice(X_scaled.shape[0], size=min(100, X_scaled.shape[0]), replace=False)]\n",
    "    X_shap = X_scaled[:min(300, X_scaled.shape[0])]\n",
    "\n",
    "    explainer = shap.KernelExplainer(predict_wrapper, X_background)\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    shap_df = pd.DataFrame({\n",
    "        \"Variable\": selected_features,\n",
    "        \"Importancia\": mean_abs_shap\n",
    "    }).sort_values(by=\"Importancia\", ascending=False)\n",
    "\n",
    "    fig_mlp = px.bar(\n",
    "        shap_df.head(15),\n",
    "        x=\"Variable\", y=\"Importancia\",\n",
    "        title=f\"Importancia SHAP (MLP) para: {producto}\",\n",
    "        labels={'Importancia': 'Importancia Media Absoluta', 'Variable': 'Variable'}\n",
    "    )\n",
    "    \n",
    "    # Métricas de Regresión de modelos\n",
    "    metricas_data = [\n",
    "        {\"Modelo\": \"Regresión Lineal\", \"R²\": round(r2_lr, 4), \"MAE\": round(mae_lr, 2), \"RMSE\": round(rmse_lr, 2)},\n",
    "        {\"Modelo\": \"Random Forest\", \"R²\": round(r2_rf, 4), \"MAE\": round(mae_rf, 2), \"RMSE\": round(rmse_rf, 2)},\n",
    "        {\"Modelo\": \"XGBoost\", \"R²\": round(r2_xgb, 4), \"MAE\": round(mae_xgb, 2), \"RMSE\": round(rmse_xgb, 2)},\n",
    "        {\"Modelo\": \"LightGBM\", \"R²\": round(r2_lgbm, 4), \"MAE\": round(mae_lgbm, 2), \"RMSE\": round(rmse_lgbm, 2)},\n",
    "        {\"Modelo\": \"MLP\", \"R²\": round(r2_mlp, 4), \"MAE\": round(mae_mlp, 2), \"RMSE\": round(rmse_mlp, 2)},\n",
    "    ]\n",
    "\n",
    "    score_text = html.Div([\n",
    "        html.H4(\"Métricas de Evaluación de Modelos\", style={'marginBottom': '15px'}),\n",
    "        dash_table.DataTable(\n",
    "            columns=[\n",
    "                {\"name\": \"Modelo\", \"id\": \"Modelo\"},\n",
    "                {\"name\": \"R²\", \"id\": \"R²\"},\n",
    "                {\"name\": \"MAE\", \"id\": \"MAE\"},\n",
    "                {\"name\": \"RMSE\", \"id\": \"RMSE\"}\n",
    "            ],\n",
    "            data=metricas_data,\n",
    "            style_cell={'textAlign': 'center', 'fontFamily': 'Arial'},\n",
    "            style_header={'backgroundColor': '#f0f0f0', 'fontWeight': 'bold'},\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            page_size=5\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "\n",
    "    return fig_lineal, fig_lineal_inversa, fig_nolineal, fig_xgBoost, fig_lightGBM, fig_mlp, fig_cluster, score_text\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('shap-img-rf', 'src'), Output('shap-img-xgb', 'src'), Output('shap-img-lgbm', 'src')],\n",
    "    Input('producto-shap-dropdown', 'value')\n",
    ")\n",
    "def update_shap_tab_all(producto):\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    q1, q3 = df_filtered[producto].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    df_filtered = df_filtered[(df_filtered[producto] >= q1 - 1.5 * iqr) & (df_filtered[producto] <= q3 + 1.5 * iqr)]\n",
    "\n",
    "    X = df_filtered[feature_cols]\n",
    "    y = df_filtered[producto]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    explainer_rf = shap.Explainer(rf)\n",
    "    shap_values_rf = explainer_rf(X_test)\n",
    "    fig_rf, ax = plt.subplots(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values_rf, X_test, feature_names=X.columns.tolist(), max_display=10, show=False)\n",
    "    buf_rf = io.BytesIO()\n",
    "    plt.savefig(buf_rf, format=\"png\", bbox_inches='tight')\n",
    "    plt.close(fig_rf)\n",
    "    shap_img_rf = base64.b64encode(buf_rf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    explainer_xgb = shap.Explainer(xgb)\n",
    "    shap_values_xgb = explainer_xgb(X_test)\n",
    "    fig_xgb, ax = plt.subplots(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values_xgb, X_test, feature_names=X.columns.tolist(), max_display=10, show=False)\n",
    "    buf_xgb = io.BytesIO()\n",
    "    plt.savefig(buf_xgb, format=\"png\", bbox_inches='tight')\n",
    "    plt.close(fig_xgb)\n",
    "    shap_img_xgb = base64.b64encode(buf_xgb.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    # LightGBM\n",
    "    lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    explainer_lgbm = shap.Explainer(lgbm)\n",
    "    shap_values_lgbm = explainer_lgbm(X_test)\n",
    "    fig_lgbm, ax = plt.subplots(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values_lgbm, X_test, feature_names=X.columns.tolist(), max_display=10, show=False)\n",
    "    buf_lgbm = io.BytesIO()\n",
    "    plt.savefig(buf_lgbm, format=\"png\", bbox_inches='tight')\n",
    "    plt.close(fig_lgbm)\n",
    "    shap_img_lgbm = base64.b64encode(buf_lgbm.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    return (\n",
    "        \"data:image/png;base64,\" + shap_img_rf,\n",
    "        \"data:image/png;base64,\" + shap_img_xgb,\n",
    "        \"data:image/png;base64,\" + shap_img_lgbm\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('grafico-estacionalidad', 'figure'),\n",
    "    Input('producto-clima-dropdown', 'value')\n",
    ")\n",
    "def update_estacionalidad(producto):\n",
    "    dias_semana = [col for col in df.columns if col.startswith('nombre_dia_')]\n",
    "    estacional = df[dias_semana + [producto]].copy()\n",
    "    for col in dias_semana:\n",
    "        estacional[col] = estacional[col].astype(int)\n",
    "    df_estacionalidad = estacional[dias_semana].multiply(estacional[producto], axis=0).sum().sort_values(ascending=False)\n",
    "    fig = px.bar(df_estacionalidad, title=f\"Ventas por Día de la Semana para: {producto}\",\n",
    "                 labels={'value': 'Ventas acumuladas', 'index': 'Día de la semana'})\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('grafico-impacto-clima', 'figure'),\n",
    "    [Input('producto-clima-dropdown', 'value'),\n",
    "     Input('clima-variable-dropdown', 'value')]\n",
    ")\n",
    "def update_impacto_clima(producto, variable):\n",
    "    fig = px.scatter(df, x=variable, y=producto,\n",
    "                     trendline='ols',\n",
    "                     title=f\"Impacto de {variable} en ventas de {producto}\",\n",
    "                     labels={variable: variable, producto: 'Ventas'})\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    [Output('prediccion-ventas', 'figure'),\n",
    "     Output('tabla-predicciones-container', 'children')],\n",
    "    [Input('producto-prediccion-dropdown', 'value'),\n",
    "     Input('modelo-prediccion-dropdown', 'value')]\n",
    ")\n",
    "def update_prediccion(producto, modelo):\n",
    "    df_model = df[['date', producto]].dropna().copy()\n",
    "    df_model['date'] = pd.to_datetime(df_model['date'])\n",
    "    df_model = df_model.sort_values('date')\n",
    "    df_model['day'] = (df_model['date'] - df_model['date'].min()).dt.days\n",
    "\n",
    "    future_days = 30\n",
    "    future_dates = pd.date_range(df_model['date'].max() + pd.Timedelta(days=1), periods=future_days)\n",
    "\n",
    "    if modelo == 'prophet':\n",
    "        df_prophet = df_model.rename(columns={'date': 'ds', producto: 'y'})\n",
    "        model = Prophet()\n",
    "        model.fit(df_prophet)\n",
    "        future = model.make_future_dataframe(periods=future_days)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        fig = px.line(forecast, x='ds', y='yhat', title=f\"Predicción de Ventas - {producto} (Prophet)\")\n",
    "        fig.add_scatter(x=df_prophet['ds'], y=df_prophet['y'], mode='markers', name='Histórico')\n",
    "\n",
    "        tabla = dash_table.DataTable(\n",
    "            columns=[\n",
    "                {'name': 'Fecha', 'id': 'ds'},\n",
    "                {'name': 'Predicción', 'id': 'yhat'},\n",
    "                {'name': 'Inferior', 'id': 'yhat_lower'},\n",
    "                {'name': 'Superior', 'id': 'yhat_upper'}\n",
    "            ],\n",
    "            data=forecast.tail(7)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].round(2).to_dict('records'),\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            style_cell={'textAlign': 'center'},\n",
    "            style_header={'fontWeight': 'bold'},\n",
    "            page_size=7\n",
    "        )\n",
    "\n",
    "        return fig, tabla\n",
    "\n",
    "    # Modelos ML\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    X = df_model[['day']]\n",
    "    y = df_model[[producto]]\n",
    "\n",
    "    scaler_X = RobustScaler()\n",
    "    scaler_y = RobustScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "    X_future = pd.DataFrame({'day': np.arange(X['day'].max() + 1, X['day'].max() + future_days + 1)})\n",
    "    X_future_scaled = scaler_X.transform(X_future)\n",
    "\n",
    "    if modelo == 'ridge':\n",
    "        model = Ridge()\n",
    "        model.fit(X_scaled, y_scaled.ravel())\n",
    "        y_pred = model.predict(X_future_scaled).reshape(-1, 1)\n",
    "\n",
    "    elif modelo == 'rf':\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_scaled, y_scaled.ravel())\n",
    "        y_pred = model.predict(X_future_scaled).reshape(-1, 1)\n",
    "\n",
    "    elif modelo == 'xgb':\n",
    "        model = XGBRegressor()\n",
    "        model.fit(X_scaled, y_scaled.ravel())\n",
    "        y_pred = model.predict(X_future_scaled).reshape(-1, 1)\n",
    "\n",
    "    elif modelo == 'lgbm':\n",
    "        model = LGBMRegressor()\n",
    "        model.fit(X_scaled, y_scaled.ravel())\n",
    "        y_pred = model.predict(X_future_scaled).reshape(-1, 1)\n",
    "\n",
    "    elif modelo == 'mlp':\n",
    "        import torch.nn as nn\n",
    "        import torch\n",
    "\n",
    "        class MLP(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.model = nn.Sequential(\n",
    "                    nn.Linear(1, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, 1)\n",
    "                )\n",
    "            def forward(self, x): return self.model(x)\n",
    "\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "        loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32, shuffle=True)\n",
    "\n",
    "        model = MLP()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for _ in range(150):\n",
    "            for xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_fn(model(xb), yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_future_tensor = torch.tensor(X_future_scaled, dtype=torch.float32)\n",
    "            y_pred = model(X_future_tensor).numpy()\n",
    "\n",
    "    y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "    fig = px.line(df_model, x='date', y=producto, title=f\"Predicción de Ventas - {producto} ({modelo.upper()})\")\n",
    "    fig.add_scatter(x=future_dates, y=y_pred_inv.flatten(), mode='lines+markers', name='Predicción futura')\n",
    "\n",
    "    tabla = html.Div(\"Tabla solo disponible para el modelo Prophet.\", style={'marginTop': '10px', 'color': 'gray'})\n",
    "\n",
    "    return fig, tabla\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('evolucion-ventas-producto', 'figure'),\n",
    "    Input('producto-evolucion-dropdown', 'value')\n",
    ")\n",
    "def update_evolucion_ventas_producto(producto):\n",
    "    fig = px.line(df, x='date', y=producto, title=f\"Evolución de Ventas - {producto}\")\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
